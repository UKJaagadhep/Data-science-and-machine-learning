{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNntI06LVjT5gpE92qYTpcx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UKJaagadhep/Data-science-and-machine-learning/blob/main/Neural_Machine_Translation/English_to_French_Neural_Machine_Translation_using_Transformers(from_scratch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Layer, Embedding, MultiHeadAttention, Dense, LayerNormalization, Input, Dropout, TextVectorization\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N3xBtlZewjTS"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF98plgX7Trt",
        "outputId": "14b9200e-24aa-47ae-9d24-0240c901db24"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-15 11:08:30--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip.1’\n",
            "\n",
            "fra-eng.zip.1       100%[===================>]   7.57M  15.9MB/s    in 0.5s    \n",
            "\n",
            "2024-05-15 11:08:31 (15.9 MB/s) - ‘fra-eng.zip.1’ saved [7943074/7943074]\n",
            "\n",
            "Archive:  /content/fra-eng.zip\n",
            "replace /content/dataset/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPARATION**"
      ],
      "metadata": {
        "id": "cZ87gMPz7h4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset = tf.data.TextLineDataset('/content/dataset/fra.txt')"
      ],
      "metadata": {
        "id": "TXvplbRf7hPp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  split_text = tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1' : split_text[0:1], 'input_2' : 'starttoken ' + split_text[1:2]}, split_text[1:2] + ' endtoken'\n",
        "  #We specify [0:1] instead of just [0] to get output in the form of a vector (enclosed by []) and not a scaler\n",
        "  #Dictionary contains inputs and  split_text[1:2] + ' [end]' is output\n",
        "  '''So for each sentence in french sequence, we will have [start] token and the sentence representing inputs to the\n",
        "  French output RNN from itself within the dictionary and we will also have the sentence and [end] token representing\n",
        "  the outputs from the French output RNN'''\n",
        "print(selector('Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4hRxMAs8cua",
        "outputId": "fd61f47d-adbe-4d88-d1c9-53145551d796"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = text_dataset.map(selector) #We use split dataset into inputs and outputs (only input_1 is given by user)"
      ],
      "metadata": {
        "id": "20cHNZs18gIn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separator(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return split_text[0:1], 'starttoken ' + split_text[1:2] + ' endtoken'"
      ],
      "metadata": {
        "id": "q7A7etnd8iza"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_dataset = text_dataset.map(separator)\n",
        "#We split dataset into english and french (alongwith starttoken and endtoken for french) to get the vocabulary for the 2 languages"
      ],
      "metadata": {
        "id": "fr0755v98lFZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 20000\n",
        "english_sequence_length = 64\n",
        "french_sequence_length = 64\n",
        "embedding_dimension = 300\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "d9VOvn498nFH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorization_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = vocabulary_size,\n",
        "    output_sequence_length = english_sequence_length,\n",
        "    output_mode = 'int'\n",
        ")"
      ],
      "metadata": {
        "id": "S300QaO88pP3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorization_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = vocabulary_size,\n",
        "    output_sequence_length = french_sequence_length,\n",
        "    output_mode = 'int'\n",
        ")"
      ],
      "metadata": {
        "id": "ZWNaspfn8rFh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_training_data = init_dataset.map(lambda x, y : x)\n",
        "english_vectorization_layer.adapt(english_training_data)"
      ],
      "metadata": {
        "id": "4XBepfBx8tLr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_training_data = init_dataset.map(lambda x, y : y)\n",
        "french_vectorization_layer.adapt(french_training_data)"
      ],
      "metadata": {
        "id": "KfpTXwao8vpk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer(inputs, output):\n",
        "  return {'input_1' : english_vectorization_layer(inputs['input_1']),\n",
        "          'input_2' : french_vectorization_layer(inputs['input_2'])}, french_vectorization_layer(output)"
      ],
      "metadata": {
        "id": "jkAV3LXd8yQD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = split_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "JRvVxznp803B"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking indeices for starttoken and endtoken\n",
        "print(french_vectorization_layer.get_vocabulary()[2])\n",
        "print(french_vectorization_layer.get_vocabulary()[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc1B6ggc83GD",
        "outputId": "20a881ab-9782-4b04-e2f7-9d82e79b9209"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starttoken\n",
            "endtoken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(2048).unbatch().batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "QwrwjBdo87uT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = int(200000/batch_size)\n",
        "print(num_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2tXDylF8_l7",
        "outputId": "2b76e802-37a9-494f-ce97-7f0685a1c5f5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(int(0.88 * num_batches))\n",
        "temp_dataset = dataset.skip(int(0.88 * num_batches))\n",
        "val_dataset = temp_dataset.take(int(0.67 * num_batches))\n",
        "test_dataset = temp_dataset.skip(int(0.67 * num_batches))"
      ],
      "metadata": {
        "id": "Swyf4_2m9AQH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgbV_Kf69CR_",
        "outputId": "db839f7c-e25b-457a-aca3-e5457ed28c07"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkVrHEif9IV7",
        "outputId": "feece6dd-6b62-4a61-e3ad-95986be06a46"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grxEAtPx9KUV",
        "outputId": "712ede86-3775-409c-dc5a-9041b4dcb3cc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoW_Alyu9MC0",
        "outputId": "21afc666-7195-4d2c-bcd8-25fe03e5d63a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELLING**"
      ],
      "metadata": {
        "id": "GfRjtxo2u5US"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **POSITIONAL ENCODING**"
      ],
      "metadata": {
        "id": "p2okOiavvAJO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ye55O8s9OBtT"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(d_model, sequence_length):\n",
        "  outputs = []\n",
        "  for pos in range(sequence_length):\n",
        "    PE = np.zeros((d_model))\n",
        "    for i in range(d_model):\n",
        "      if i % 2 == 0:\n",
        "        PE[i] = np.sin(pos / (10000 ** (i / d_model)))\n",
        "      else:\n",
        "        PE[i] = np.cos(pos / (10000 ** ((i - 1)/ d_model)))\n",
        "    outputs.append(tf.expand_dims(PE, axis = 0)) #shape = [1, d_model]\n",
        "  out = tf.concat(outputs, axis = 0) #shape = [sequence_length, d_model]\n",
        "  out = tf.expand_dims(out, axis = 0) #shape = [1, sequence_length, d_model]\n",
        "  return tf.cast(out, dtype = tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(positional_encoding(256, 64).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZkA2QYrwrMf",
        "outputId": "2c0493d3-0898-488e-a207-7c1dcf0eee55"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EMBEDDINGS**"
      ],
      "metadata": {
        "id": "-y6kl7PpGhaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocabulary_size, embedding_dimension):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.embedding = Embedding(vocabulary_size, embedding_dimension)\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "    self.embedding_dimension = embedding_dimension\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens = self.embedding(inputs)\n",
        "    embedded_positions = positional_encoding(self.embedding_dimension, self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask = None):\n",
        "    return tf.math.not_equal(inputs, 0) #To avoid computation for places in the sequence where value is 0 (no word) as they don't contain any info\n",
        "    #True if element in inputs not equal to 0 and False if element in inputs equal to 0"
      ],
      "metadata": {
        "id": "PexTpc33xA4n"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=tf.constant([[2,4,7,21,3,5,0,0]])\n",
        "emb=Embeddings(8,20000,512)\n",
        "emb_out=emb(test_input)\n",
        "print(emb_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSdH9mJb5kYx",
        "outputId": "e8a1ecfa-96cc-4e9e-92e2-bedb001e97eb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = emb.compute_mask(test_input)\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr6d2aLL5l_H",
        "outputId": "39058ac4-e5f3-43eb-c90e-c38c9f064aec"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ True  True  True  True  True  True False False]], shape=(1, 8), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(mask, dtype = tf.int32)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLjRZQmVBzJZ",
        "outputId": "7b9b68f9-7551-4ea4-c5de-3ae514e78e2a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding batch dimension\n",
        "mask = mask[:, tf.newaxis, :]\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-PTWsG0DvpB",
        "outputId": "f81e8065-f607-4fbd-90fd-ab407e7a638a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[[1 1 1 1 1 1 0 0]]], shape=(1, 1, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To repeat mask across the decoder sequence length so that each timestep has a mask\n",
        "mask = tf.repeat(mask, 4, axis = 1)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djWb-1I3ENju",
        "outputId": "10a509e0-17d6-4a35-9273-fd8cac4658d5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 8), dtype=int32, numpy=\n",
              "array([[[1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 0, 0]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TRANSFORMER ENCODER**"
      ],
      "metadata": {
        "id": "LSajIeADGkf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "  def __init__(self, embedding_dimension, inner_dense_dimension, num_heads):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "\n",
        "    self.mh_attention = MultiHeadAttention(num_heads = num_heads, key_dim = embedding_dimension)\n",
        "    #num_heads is no. of self attention units in multi head attention\n",
        "\n",
        "    self.norm1 = LayerNormalization()\n",
        "    self.norm2 = LayerNormalization()\n",
        "\n",
        "    self.feed_forward = Sequential([\n",
        "        Dense(inner_dense_dimension, activation = 'relu'),\n",
        "        Dense(embedding_dimension)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, mask = None):\n",
        "    if mask is not None: #mask shape = [batch_size, sequence_length]\n",
        "      mask = tf.cast(mask, dtype = tf.int32) #Converting from True and False to 1 and 0\n",
        "      mask = mask[:, tf.newaxis, :] #Adding a dimension\n",
        "      sequence_length = mask.shape[2]\n",
        "      padding_mask = tf.repeat(mask, sequence_length, axis = 1) #To get mask of shape = [batch_size, sequence_length, sequence_length] which is the shape of attention weight matrix\n",
        "\n",
        "    attention_output = self.mh_attention(key = inputs, query = inputs, value = inputs, attention_mask = padding_mask)\n",
        "\n",
        "    add_norm_and_feed_forward_input = self.norm1(inputs + attention_output)\n",
        "\n",
        "    feed_forward_output = self.feed_forward(add_norm_and_feed_forward_input)\n",
        "\n",
        "    return self.norm2(add_norm_and_feed_forward_input + feed_forward_output)"
      ],
      "metadata": {
        "id": "y0MP_GtmEiPZ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(512, 2048, 8)\n",
        "encoder_outputs = encoder(emb_out)\n",
        "print(encoder_outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFcGxN2L5V1",
        "outputId": "6369e72c-e58e-4585-c136-091f50c456c6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TRANSFORMER DECODER**"
      ],
      "metadata": {
        "id": "EKAtA8gxMkCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.ones([1, 8, 8], dtype = tf.int32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVCjo0w3L3lo",
        "outputId": "9817ea54-15bf-4b34-bf94-1d3dd47a03d5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.linalg.band_part(\n",
        "        tf.ones([1, 8, 8],dtype = tf.int32), -1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC67EPd7LtaC",
        "outputId": "cd22b4cf-ded7-4333-f62c-b77bab014103"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embedding_dimension, inner_dense_dimension, num_heads):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "\n",
        "    self.mh_attention = MultiHeadAttention(num_heads = num_heads, key_dim = embedding_dimension)\n",
        "    self.masked_mh_attention = MultiHeadAttention(num_heads = num_heads, key_dim = embedding_dimension)\n",
        "\n",
        "    self.norm1 = LayerNormalization()\n",
        "    self.norm2 = LayerNormalization()\n",
        "    self.norm3 = LayerNormalization()\n",
        "\n",
        "    self.feed_forward = Sequential([\n",
        "        Dense(inner_dense_dimension, activation = 'relu'),\n",
        "        Dense(embedding_dimension)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, encoder_outputs, encoder_mask, mask = None):\n",
        "    if mask is not None:\n",
        "\n",
        "      #Masks for masked multi head attention\n",
        "      #For causal mask\n",
        "      causal_mask = tf.linalg.band_part(\n",
        "          tf.ones([tf.shape(inputs)[0], #batch_size\n",
        "                   tf.shape(inputs)[1], #sequence_length\n",
        "                   tf.shape(inputs)[1]], dtype = tf.int32),\n",
        "          -1, 0 #band_part specifications to get lower triangular martrix fro causal mask\n",
        "      )\n",
        "      #For padding mask\n",
        "      mask = tf.cast(mask, dtype = tf.int32)\n",
        "      mask = mask[:, tf.newaxis, :]\n",
        "      sequence_length = mask.shape[2]\n",
        "      padding_mask = tf.repeat(mask, sequence_length, axis = 1)\n",
        "      #Combined mask\n",
        "      combined_mask = tf.minimum(causal_mask, padding_mask)\n",
        "\n",
        "      #Masks for multi head attention\n",
        "      enc_mask = tf.cast(encoder_mask[:, tf.newaxis, :], dtype = \"int32\")\n",
        "      cross_attn_mask = tf.repeat(enc_mask, sequence_length, axis = 1)\n",
        "\n",
        "    masked_attention_output = self.masked_mh_attention(key = inputs, query = inputs, value = inputs, attention_mask = combined_mask)\n",
        "    add_norm_1 = self.norm1(inputs + masked_attention_output)\n",
        "    attention_2_output, scores = self.mh_attention(query = add_norm_1, key = encoder_outputs, value = encoder_outputs, attention_mask = cross_attn_mask, return_attention_scores = True)\n",
        "    add_norm_2 = self.norm2(add_norm_1 + attention_2_output)\n",
        "    feed_forward_output = self.feed_forward(add_norm_2)\n",
        "    return self.norm3(add_norm_2 + feed_forward_output) #, scores #Output scores to visualize attention"
      ],
      "metadata": {
        "id": "9iyAgyD_L6ZM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_mask = mask\n",
        "decoder_outputs = TransformerDecoder(512, 2048, 4)(emb_out, encoder_outputs, enc_mask)\n",
        "print(decoder_outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-eHNWd7Rxh-",
        "outputId": "437926c7-37a5-4bce-ead7-7bcd0ac49cb5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TRANSFORMER**"
      ],
      "metadata": {
        "id": "AOA1EYcXRu7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 512\n",
        "feed_forward_inner_dimension = 2048\n",
        "num_heads = 8\n",
        "num_layers = 1\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "zokkDApZRuVJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape = (english_sequence_length,), dtype = \"int64\", name = \"input_1\")\n",
        "embedding = Embeddings(english_sequence_length, vocabulary_size, embedding_dimension)\n",
        "x = embedding(encoder_inputs)\n",
        "encoder_mask = embedding.compute_mask(encoder_inputs)\n",
        "\n",
        "for i in range(num_layers):\n",
        "  x = TransformerEncoder(embedding_dimension, feed_forward_inner_dimension, num_heads)(x)\n",
        "encoder_outputs = x\n",
        "\n",
        "decoder_inputs = Input(shape = (french_sequence_length,), dtype = \"int64\", name = \"input_2\")\n",
        "x = Embeddings(french_sequence_length, vocabulary_size, embedding_dimension)(decoder_inputs)\n",
        "for j in range(num_layers):\n",
        "  x = TransformerDecoder(embedding_dimension, feed_forward_inner_dimension, num_heads)(x, encoder_outputs, encoder_mask)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "decoder_outputs = Dense(vocabulary_size, activation = \"softmax\")(x)\n",
        "\n",
        "Transformer = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
        "\n",
        "Transformer.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oxjVBQlULrX",
        "outputId": "41b80c8f-f101-4d37-9e23-051f9d14c8b0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " embeddings_20 (Embeddings)  (None, 64, 512)              1024000   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " embeddings_21 (Embeddings)  (None, 64, 512)              1024000   ['input_2[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " transformer_encoder_14 (Tr  (None, 64, 512)              1050316   ['embeddings_20[0][0]']       \n",
            " ansformerEncoder)                                        8                                       \n",
            "                                                                                                  \n",
            " tf.math.not_equal_12 (TFOp  (None, 64)                   0         ['input_1[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " transformer_decoder_9 (Tra  (None, 64, 512)              1890560   ['embeddings_21[0][0]',       \n",
            " nsformerDecoder)                                         0          'transformer_encoder_14[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'tf.math.not_equal_12[0][0]']\n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 64, 512)              0         ['transformer_decoder_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_52 (Dense)            (None, 64, 20000)            1026000   ['dropout_12[0][0]']          \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 60148768 (229.45 MB)\n",
            "Trainable params: 60148768 (229.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom Self Attention**"
      ],
      "metadata": {
        "id": "9kIbfwZ9M_Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self, model_size):\n",
        "    super(CustomSelfAttention, self).__init__()\n",
        "    self.model_size = model_size\n",
        "  def call(self, query, key, value, masking):\n",
        "    #Compute scores\n",
        "    score = tf.matmul(query, key, transpose_b = True)\n",
        "\n",
        "    #Scaling\n",
        "    score /= tf.math.sqrt(tf.cast(self.model_size, tf.float32))\n",
        "\n",
        "    #Masking\n",
        "    masking = tf.cast(masking, dtype = tf.float32)\n",
        "    score += (1. - masking) * -1e10\n",
        "    # 1. - masking gives an inverted mask where all 0s are 1s and all 1s are 0s\n",
        "    #We multiply the mask by a large negative number to convert the numbers in scores where original mask is 0 to large negative numbers\n",
        "    #The softmax of large negative numbers is almost 0 and most of the value (totalling to 1) is concentrated in the elements where original mash is 1\n",
        "\n",
        "    #Attention_weights\n",
        "    attention = tf.nn.softmax(score, axis = -1) * masking\n",
        "    #We multiply by masking to solve the situation when all the elements in the row in original mash is 0\n",
        "    #In this case, since all row elements are large negative numbers softmax sum 1 will be shared equally among them instead of all being masked to 0\n",
        "\n",
        "    #Output\n",
        "    head = tf.matmul(attention, value)\n",
        "    return head"
      ],
      "metadata": {
        "id": "smZJO7rxNDZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom Multi Head Attention**"
      ],
      "metadata": {
        "id": "Aoh7m2bAQYQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMultiHeadAttention(Layer):\n",
        "  def __init__(self, num_heads, key_dim):\n",
        "    super(CustomMultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.num_heads = num_heads\n",
        "    self.dense_q = [Dense(key_dim // num_heads) for _ in range(num_heads)]\n",
        "    self.dense_k = [Dense(key_dim // num_heads) for _ in range(num_heads)]\n",
        "    self.dense_v = [Dense(key_dim // num_heads) for _ in range(num_heads)]\n",
        "    self.dense_o = Dense(key_dim)\n",
        "    self.self_attention = CustomSelfAttention(key_dim)\n",
        "\n",
        "  def call(self, query, key, value, attention_mask):\n",
        "    heads = []\n",
        "\n",
        "    for i in range(self.num_heads):\n",
        "      head = self.self_attention(self.dense_q[i](query), self.dense_k[i](key),\n",
        "                              self.dense_v[i](value), attention_mask)\n",
        "      heads.append(head)\n",
        "    heads = tf.concat(heads, axis = 2)\n",
        "    heads = self.dense_o(heads)\n",
        "    return heads"
      ],
      "metadata": {
        "id": "hgTKwUAiQX16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "id": "TcNpXVYQEUYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "EeuBAzpuzODH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scheduler(LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps):\n",
        "    super(Scheduler, self).__init__()\n",
        "    self.d_model = tf.cast(d_model, tf.float64)\n",
        "    self.warmup_steps = tf.cast(warmup_steps, dtype = tf.float64)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype = tf.float64) #Since we multiply by decimals like 0.5, 1.5 etc\n",
        "    return (self.d_model ** (-0.5)) * tf.math.minimum(step ** (-0.5), step * (self.warmup_steps ** -1.5))"
      ],
      "metadata": {
        "id": "BuND3hPd4lsF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_steps = 4000\n",
        "lr_scheduled = Scheduler(embedding_dimension, warmup_steps)"
      ],
      "metadata": {
        "id": "-mEdGQXAHLMu"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transformer.compile(\n",
        "    loss = SparseCategoricalCrossentropy(),\n",
        "    optimizer = Adam(lr_scheduled, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9),)\n",
        "    #metrics = [BLEU()],\n",
        "    #run_eagerly = True)"
      ],
      "metadata": {
        "id": "6DpiMM2lHb5_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/transformers.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    monitor = 'val_loss',\n",
        "    mode = 'min',\n",
        "    save_best_only = True)"
      ],
      "metadata": {
        "id": "2ZaxLxq3J7Q4"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = Transformer.fit(\n",
        "    train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    epochs = 2,\n",
        "    callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pykQZbKbJXwi",
        "outputId": "e4ba4981-9250-4515-839c-c9b714347211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "    395/Unknown - 10864s 27s/step - loss: 3.1833"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Transformer.save_weights('/content/transformers_weights.h5')"
      ],
      "metadata": {
        "id": "AnoPNWgUJmv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JrmOKcL7Jor6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RP8u600XJwRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transformer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "4E4Bc8G2JzWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING**"
      ],
      "metadata": {
        "id": "aOhPKvkNKMHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {x:y for x, y in zip(range(len(french_vectorization_layer.get_vocabulary())), french_vectorization_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "7V-8pufFKLmJ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {y:x for x, y in zip(range(len(french_vectorization_layer.get_vocabulary())), french_vectorization_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "WQrONLWlKRH0"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence = english_vectorization_layer([english_sentence])\n",
        "  shifted_target = 'starttoken'\n",
        "\n",
        "  for i in range(french_sequence_length):\n",
        "    tokenized_shifted_target = french_vectorization_layer([shifted_target])\n",
        "    output = Transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index = tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word = index_to_word[french_word_index]\n",
        "    if current_word == 'endtoken':\n",
        "      break\n",
        "    shifted_target += ' ' + current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "XbZn545HKTVO"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Everyone should water his or her tomato plants')"
      ],
      "metadata": {
        "id": "nU08PWsyKZU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZING ATTENTION WEIGHTS"
      ],
      "metadata": {
        "id": "LhwzU-r0zms8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken je lai fait très bien'\n",
        "\n",
        "  tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "  attention_weights=attention_score_model.predict([tokenized_english_sentence,\n",
        "                                                   tokenized_shifted_target])\n",
        "\n",
        "  return attention_weights\n",
        "\n",
        "out=visualize('I did it very well')\n"
      ],
      "metadata": {
        "id": "MVgo-tn2zq31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out['decoder_layer1_block2'][0].shape)"
      ],
      "metadata": {
        "id": "cJF8ZyyEzr19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,12))\n",
        "\n",
        "for i in range(NUM_HEADS):\n",
        "  ax = plt.subplot(2,4, i+1)\n",
        "\n",
        "  plt.imshow(out['decoder_layer1_block2'][0][i][0:10,0:10])\n",
        "  plt.title(\"Attention Scores for head:->\"+str(i+1))"
      ],
      "metadata": {
        "id": "1er85VM8zvWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}